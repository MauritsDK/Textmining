{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and splitting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning out empty comments:\n",
    "empty_comments = data[\"comment\"].isna()\n",
    "empty_comments = data[empty_comments].index\n",
    "data.drop(empty_comments, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train, c_test, l_train, l_test = train_test_split(data[\"comment\"], data[\"label\"], test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bag of Words**\n",
    "#### CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec = CountVectorizer(min_df=1, # in how many documents the term minimally occurs\n",
    "                             tokenizer=nltk.word_tokenize) # nltk tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_vector_data = c_vec.fit_transform(c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_classifier = svm.LinearSVC()\n",
    "lin_classifier.fit(com_vector_data,l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector_data = c_vec.transform(c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lin_classifier.predict(test_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.684     0.721     0.702    151624\n",
      "           1      0.705     0.668     0.686    151608\n",
      "\n",
      "    accuracy                          0.694    303232\n",
      "   macro avg      0.695     0.694     0.694    303232\n",
      "weighted avg      0.695     0.694     0.694    303232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report1 = classification_report(l_test,prediction,digits = 3)\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(com_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_classifier2 = svm.LinearSVC()\n",
    "lin_classifier2.fit(train_tfidf,l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = tfidf_transformer.transform(test_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = lin_classifier2.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.688     0.714     0.701    151624\n",
      "           1      0.702     0.676     0.689    151608\n",
      "\n",
      "    accuracy                          0.695    303232\n",
      "   macro avg      0.695     0.695     0.695    303232\n",
      "weighted avg      0.695     0.695     0.695    303232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report2 = classification_report(l_test,predicted2,digits = 3)\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "#### similarity between the vectorized training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product = 2.294, normalized BoW = 2.449, normalized tfidf = 1.000, cosine similarity = 0.936\n"
     ]
    }
   ],
   "source": [
    "#print(cv_array.shape)\n",
    "#print(tfidf_array.shape)\n",
    "\n",
    "cv_array = com_vector_data[0].toarray()\n",
    "tfidf_array = train_tfidf[0].toarray()\n",
    "\n",
    "cv_array = cv_array.flatten()\n",
    "tfidf_array = tfidf_array.flatten()\n",
    "\n",
    "# manually compute cosine similarity\n",
    "dot = numpy.dot(cv_array, tfidf_array)\n",
    "norm_BoW = numpy.linalg.norm(cv_array)\n",
    "norm_tfidf = numpy.linalg.norm(tfidf_array)\n",
    "cos = dot / (norm_BoW * norm_tfidf)\n",
    " \n",
    "print('Dot product = %.3f, normalized BoW = %.3f, normalized tfidf = %.3f, cosine similarity = %.3f' %(dot,norm_BoW, norm_tfidf,cos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### similarity between predictions of both vectorisation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product = 135355.000, normalized BoW = 378.918, normalized tfidf = 381.965, cosine similarity = 0.935\n"
     ]
    }
   ],
   "source": [
    "#print(predictions.shape)\n",
    "#print(predicted2.shape)\n",
    "\n",
    "# manually compute cosine similarity\n",
    "dot = numpy.dot(prediction, predicted2)\n",
    "norm_BoW = numpy.linalg.norm(prediction)\n",
    "norm_tfidf = numpy.linalg.norm(predicted2)\n",
    "cos = dot / (norm_BoW * norm_tfidf)\n",
    " \n",
    "print('Dot product = %.3f, normalized BoW = %.3f, normalized tfidf = %.3f, cosine similarity = %.3f' %(dot,norm_BoW, norm_tfidf,cos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hetzelfde maar zonder stopwoorden**\n",
    "\n",
    "#### Countvectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec2= CountVectorizer(min_df=1,\n",
    "                             tokenizer=nltk.word_tokenize, \n",
    "                             stop_words=stopwords.words('english')) # stopwords are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(c_vec2.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marin\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "vectorized_com = c_vec2.fit_transform(c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_classifier3 = svm.LinearSVC()\n",
    "lin_classifier3.fit(vectorized_com,l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_test = c_vec2.transform(c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.673     0.710     0.691    151624\n",
      "           1      0.693     0.656     0.674    151608\n",
      "\n",
      "    accuracy                          0.683    303232\n",
      "   macro avg      0.683     0.683     0.682    303232\n",
      "weighted avg      0.683     0.683     0.682    303232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = lin_classifier3.predict(vectorized_test)\n",
    "report3 = classification_report(l_test,predicted,digits = 3)\n",
    "print(report3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf2 = tfidf_transformer.fit_transform(vectorized_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_classifier4 = svm.LinearSVC()\n",
    "lin_classifier4.fit(train_tfidf2,l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf2 = tfidf_transformer.transform(vectorized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = lin_classifier4.predict(test_tfidf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.688     0.714     0.701    151624\n",
      "           1      0.702     0.676     0.689    151608\n",
      "\n",
      "    accuracy                          0.695    303232\n",
      "   macro avg      0.695     0.695     0.695    303232\n",
      "weighted avg      0.695     0.695     0.695    303232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report4 = classification_report(l_test,predicted2,digits = 3)\n",
    "print(report4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "#### similarity between the vectorized training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product = 2.294, normalized BoW = 2.449, normalized tfidf = 1.000, cosine similarity = 0.936\n"
     ]
    }
   ],
   "source": [
    "#print(cv_array.shape)\n",
    "#print(tfidf_array.shape)\n",
    "\n",
    "cv_array2 = vectorized_com[0].toarray()\n",
    "tfidf_array2 = train_tfidf2[0].toarray()\n",
    "\n",
    "cv_array2 = cv_array.flatten()\n",
    "tfidf_array2 = tfidf_array.flatten()\n",
    "\n",
    "# manually compute cosine similarity\n",
    "dot = numpy.dot(cv_array2, tfidf_array2)\n",
    "norm_BoW = numpy.linalg.norm(cv_array2)\n",
    "norm_tfidf = numpy.linalg.norm(tfidf_array2)\n",
    "cos = dot / (norm_BoW * norm_tfidf)\n",
    " \n",
    "print('Dot product = %.3f, normalized BoW = %.3f, normalized tfidf = %.3f, cosine similarity = %.3f' %(dot,norm_BoW, norm_tfidf,cos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### similarity between predictions of both vectorisation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product = 134910.000, normalized BoW = 378.707, normalized tfidf = 382.578, cosine similarity = 0.931\n"
     ]
    }
   ],
   "source": [
    "#print(predictions.shape)\n",
    "#print(predicted2.shape)\n",
    "\n",
    "# manually compute cosine similarity\n",
    "dot = numpy.dot(prediction2, predicted)\n",
    "norm_BoW = numpy.linalg.norm(predicted)\n",
    "norm_tfidf = numpy.linalg.norm(prediction2)\n",
    "cos = dot / (norm_BoW * norm_tfidf)\n",
    " \n",
    "print('Dot product = %.3f, normalized BoW = %.3f, normalized tfidf = %.3f, cosine similarity = %.3f' %(dot,norm_BoW, norm_tfidf,cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
