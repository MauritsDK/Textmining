{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab5 - Assignment 5 about extraction of properties\n",
    "\n",
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "This notebook describes the LAB-5 assignment of the Text Mining course. It is about Property Extraction.\n",
    "\n",
    "**Due**: 17 Mar at 23:59\n",
    "\n",
    "**How to submit**: Please submit your assignment using Canvas (see *Assignments* -> *Lab Session Property Extraction*). Convert your notebook to PDF (in JupyterLab, this can be done by clicking on *File* in the menu bar, select *Export Notebook As*, then select *Export Notebook to PDF*)\n",
    "\n",
    "**Points**: each exercise is suffixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "**Assignment goals**:\n",
    "* Get insight into the challenges of entity property extraction.\n",
    "* Learn how to build a transparent property extraction method based on patterns.\n",
    "* Get insight into the pros and cons of two pattern-based property extraction methods.\n",
    "* Be able to run your extractors on unseen documents from Wikipedia.\n",
    "* Be able to evaluate property extractors.\n",
    "\n",
    "In this assignment, the main focus lies on creating your own pattern-based property extractors. You are then going to run them on Wikipedia texts, evaluate them against gold values, and reflect on their relative performance.\n",
    "\n",
    " We recommend that you go through the notebooks in the following order:\n",
    "* *Read the assignment (see below)*\n",
    "* *Lab5-Property-extraction.ipynb*\n",
    "* *Answer the questions of the assignment (see below) using the provided notebooks and submit*\n",
    "\n",
    "**Hint:** in the explanation notebook, we had an example about extraction of properties with substring matching and with dependencies. You can use much of that code here, but make sure you make the right adjustments.\n",
    "\n",
    "**Good luck & have fun!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import lab5_utils as utils\n",
    "\n",
    "model=\"en_core_web_sm\"\n",
    "\n",
    "nlp = spacy.load(model)\n",
    "# print(\"Info: Loaded model '%s'\" % model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting properties with substring matching (12 points)\n",
    "\n",
    "**Exercise 1a** Write code that extracts the birth year of a person by using substring matching. (4 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_birth_year_regex(doc, patterns):\n",
    "    # Extract the birth year of a person with regular expressions\n",
    "    property_value_type='DATE'\n",
    "    target_entity_type='PERSON'\n",
    "    \n",
    "    # the following 3 lines merge entities and noun chunks into one token\n",
    "    # this is useful in our cases, so we will always do it.\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "\n",
    "    relations = {}\n",
    "    \n",
    "    # step Ia - generate possible property values\n",
    "    dates=utils.get_entities_of_type(property_value_type, doc)\n",
    "    for date in dates:\n",
    "        # step Ib - is one of our patterns found before the date \n",
    "        if utils.pattern_found_on_the_left(doc, date.i, patterns):\n",
    "            # step II - find the closest entity of some target type\n",
    "            pers=utils.find_closest_entity(doc.ents, date.idx, target_entity_type)\n",
    "            # step III - normalize the year\n",
    "            year=utils.extract_year_from_date(date.text)\n",
    "            if year and pers:\n",
    "                relations[pers]=year\n",
    "\n",
    "    return relations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1b** Test your *birth year substring matching extractor* in the following way. \n",
    "\n",
    "* Write a sentence on which you expect that the extractor *WILL* work. \n",
    "* Write a sentence on which you expect that the extractor *WILL NOT* work. \n",
    "\n",
    "Run your extractor on both sentences and print the results. Make sure that the results are as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence \u001b[1m WILL\u001b[0m work: Peter was born in 1975.\n",
      "{'Peter': 1975}\n",
      "\n",
      "This sentence \u001b[1m WILL NOT\u001b[0m work: Peter Pan's dog was born in 1990\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "born_patterns=['born in', 'birthdate', 'born on']\n",
    "\n",
    "text='Peter was born in 1975.'\n",
    "text2 = \"Peter Pan's dog was born in 1990\"\n",
    "\n",
    "print( \"This sentence \\033[1m WILL\\033[0m work:\",text)\n",
    "birth_year_relations=extract_birth_year_regex(nlp(text), born_patterns)\n",
    "print(birth_year_relations)\n",
    "print()\n",
    "print( \"This sentence \\033[1m WILL NOT\\033[0m work:\",text2)\n",
    "birth_year_relations2=extract_birth_year_regex(nlp(text2), born_patterns)\n",
    "print(birth_year_relations2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1c** Write code that extracts the manufacturer of a device by using substring matching. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_manufacturer_regex(doc, patterns, main_entity):\n",
    "    # Extract the manufacturer of a device by using regular expressions\n",
    "    property_value_type='ORG'\n",
    "    target_entity_type='PRODUCT'\n",
    "    \n",
    "    # the following 3 lines merge entities and noun chunks into one token\n",
    "    # this is useful in our cases, so we will always do it.\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "\n",
    "    relations = {}\n",
    "    \n",
    "    manus =utils.get_entities_of_type(property_value_type, doc)\n",
    "    \n",
    "    for manu in manus:\n",
    "        if utils.pattern_found_on_the_left(doc, manu.i, patterns):\n",
    "            prod=utils.find_closest_entity(doc.ents, manu.idx, target_entity_type)\n",
    "            if not prod:\n",
    "                prod = main_entity\n",
    "            if manu and prod:\n",
    "                relations[prod]=manu.text\n",
    "    return relations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1d** Test your *manufacturer substring matching extractor* in the following way. \n",
    "\n",
    "* Write a sentence on which you expect that the extractor *WILL* work. \n",
    "* Write a sentence on which you expect that the extractor *WILL NOT* work. \n",
    "\n",
    "Run your extractor on both sentences and print the results. Make sure that the results are as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence \u001b[1m WILL\u001b[0m work: the iPhone was developed by Apple in 2000.\n",
      "{'iPhone': 'Apple'}\n",
      "\n",
      "This sentence \u001b[1m WILL NOT\u001b[0m work: Apple developed the iPad in 2005 .\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "manu_predicates=['manufactured', 'produced', 'developed by', 'developed']\n",
    "main_entity = 'iPhone'\n",
    "sentence='the iPhone was developed by Apple in 2000.'\n",
    "sentence2 = 'Apple developed the iPad in 2005 .'\n",
    "\n",
    "print( \"This sentence \\033[1m WILL\\033[0m work:\",sentence)\n",
    "manu_relations=extract_manufacturer_regex(nlp(sentence), manu_predicates, main_entity)\n",
    "print(manu_relations)\n",
    "print()\n",
    "print( \"This sentence \\033[1m WILL NOT\\033[0m work:\",sentence2)\n",
    "manu_relations2=extract_manufacturer_regex(nlp(sentence2), manu_predicates, main_entity)\n",
    "print(manu_relations2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting properties by using dependency information (12 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting_dependency(token, predicates):\n",
    "    \"\"\"\n",
    "    Check whether the we find the right keyword in the correct part of the dependency tree.\n",
    "    \"\"\"\n",
    "    # Find prepositional objects that have a head with dependency label 'agent'\n",
    "    # and its head has a dependency label 'acl'\n",
    "    # Also, we make sure that the head of the head of our object is one of our keywords.\n",
    "    if token.dep_ == 'nsubjpass' and token.head.dep_ == 'ROOT':\n",
    "        pred=token.head.head\n",
    "        if pred.text in predicates:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2a** Write code that extracts the birth year of a person by using dependency information. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-a784a9f790f6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-a784a9f790f6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    de(doc, predicates):\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "de(doc, predicates):\n",
    "    \n",
    "    property_value_type='PERSON'\n",
    "    target_entity_type='DATE'\n",
    "    \n",
    "    # the following 3 lines merge entities and noun chunks into one token\n",
    "    # this is useful in our cases, so we will always do it.\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "    \n",
    "    relations={}\n",
    "    \n",
    "    # step Ia - generate possible property values\n",
    "    persons=utils.get_entities_of_type(property_value_type, doc)\n",
    "    \n",
    "    for person in persons:\n",
    "        print(person)\n",
    "        # step Ib - do we find the right keyword in the correct part of the dependency tree?\n",
    "        if fitting_dependency(person, predicates):\n",
    "            # step II - find the closest entity of some target type\n",
    "            date=utils.find_closest_entity(doc.ents, person.idx, target_entity_type)\n",
    "            year =utils.extract_year_from_date(date)\n",
    "            if person and year:\n",
    "                relations[person]=year\n",
    "        else:\n",
    "            print('HELP')\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2b** Test your *birth year dependency extractor* in the following way. \n",
    "\n",
    "* Write a sentence on which you expect that the extractor *WILL* work. \n",
    "* Write a sentence on which you expect that the extractor *WILL NOT* work. \n",
    "\n",
    "Run your extractor on both sentences and print the results. Make sure that the results are as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "born_patterns=['born', 'birthdate']\n",
    "sentence='Peter was born in 1975.'\n",
    "sentence2 = \"In 1975 Peter's dog was born.\"\n",
    "\n",
    "print( \"This sentence \\033[1m WILL\\033[0m work:\",sentence)\n",
    "birth_year_relations=extract_birth_year_dep(nlp(sentence), born_patterns)\n",
    "print(birth_year_relations)\n",
    "print()\n",
    "print( \"This sentence \\033[1m WILL NOT\\033[0m work:\",sentence2)\n",
    "birth_year_relations2=extract_birth_year_dep(nlp(sentence2), born_patterns)\n",
    "print(birth_year_relations2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2c** Write code that extracts the manufacturer of a device by using dependency information. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting_dependency(token, predicates):\n",
    "    \"\"\"\n",
    "    Check whether the we find the right keyword in the correct part of the dependency tree.\n",
    "    \"\"\"\n",
    "    # Find prepositional objects that have a head with dependency label 'agent'\n",
    "    # and its head has a dependency label 'acl'\n",
    "    # Also, we make sure that the head of the head of our object is one of our keywords.\n",
    "    if token.dep_ == 'pobj' and token.head.dep_ == 'agent' and token.head.head.dep_ =='ROOT':\n",
    "        pred=token.head.head\n",
    "        if pred.text in predicates:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_manufacturer(doc, predicates, main_entity):\n",
    "    \n",
    "    property_value_type='ORG'\n",
    "    target_entity_type='PRODUCT'\n",
    "    \n",
    "    # the following 3 lines merge entities and noun chunks into one token\n",
    "    # this is useful in our cases, so we will always do it.\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "    \n",
    "    relations={}\n",
    "    \n",
    "    # step Ia - generate possible property values\n",
    "    manus=utils.get_entities_of_type(property_value_type, doc)\n",
    "    \n",
    "    for manu in manus:\n",
    "        # step Ib - do we find the right keyword in the correct part of the dependency tree?\n",
    "        if fitting_dependency(manu, predicates):\n",
    "            # step II - find the closest entity of some target type\n",
    "            device=utils.find_closest_entity(doc.ents, manu.idx, target_entity_type)\n",
    "            # Devices are often not recognized properly by SpaCy - \n",
    "            # if we find no device, we assume that the relation is about the main entity of the document\n",
    "            if not device:\n",
    "                device=main_entity\n",
    "            if device and manu:\n",
    "                relations[device]=manu.text\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2d** Test your *manufacturer dependency extractor* in the following way. \n",
    "\n",
    "* Write a sentence on which you expect that the extractor *WILL* work. \n",
    "* Write a sentence on which you expect that the extractor *WILL NOT* work. \n",
    "\n",
    "Run your extractor on both sentences and print the results. Make sure that the results are as expected. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manu_predicates=['manufactured', 'produced', 'developed']\n",
    "main_entity = 'iPhone'\n",
    "main_entity2 ='Walkman'\n",
    "sentence='the iPhone was developed by Apple in 2000.'\n",
    "sentence2 = 'Apple developed the iPad in 2005.'\n",
    "sentence3= 'Walkman is a brand of portable media players manufactured by Sony. The original Walkman, released in 1979, was a portable cassette player that changed listening habits by allowing people to listen to music of their choice on the move. It was devised by Sony founders Masaru Ibuka and Akio Morita, who felt Sony existing portable player was too unwieldy and expensive'\n",
    "print( \"This sentence \\033[1m WILL\\033[0m work:\",sentence)\n",
    "manu_relations=extract_manufacturer(nlp(sentence), manu_predicates, main_entity)\n",
    "print(manu_relations)\n",
    "\n",
    "print()\n",
    "print( \"This sentence \\033[1m WILL NOT\\033[0m work:\",sentence2)\n",
    "manu_relations2=extract_manufacturer(nlp(sentence2), manu_predicates, main_entity)\n",
    "print(manu_relations2)\n",
    "print( \"This sentence \\033[1m WILL NOT\\033[0m work:\",sentence3)\n",
    "manu_relations3=extract_manufacturer(nlp(sentence2), manu_predicates, main_entity2)\n",
    "print(manu_relations3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Running and evaluating extractors on Wikipedia (8 points)\n",
    "\n",
    "We will run our extractors on 50 documents about people and 50 documents about devices. We provide code to load the lists of entities and the gold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"birthyears.json\", 'rb') as f:\n",
    "    gold_birthyears=json.load(f)\n",
    "    wiki_people=list(gold_birthyears.keys())\n",
    "    \n",
    "with open(\"manufacturers.json\", 'rb') as f:\n",
    "    gold_manufacturers=json.load(f)\n",
    "    wiki_devices=list(gold_manufacturers.keys())\n",
    "print(wiki_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists `wiki_people` and `wiki_devices` contain the names of 50 people and 50 devices, respectively.\n",
    "\n",
    "The dictionaries `gold_birthyears` and `gold_manufacturers` contain gold values for each of these entities.\n",
    "\n",
    "We provide a function that evaluates your extracted property values against known (\"gold\") property values. The function returns three evaluation scores: precision, recall, f1-score. You can find call this function as follows:\n",
    "\n",
    "`utils.evaluate_property(system_json, gold_json)`\n",
    "\n",
    "(make sure to replace the system_json and the gold_json with the concrete dictionaries you are comparing, depending on the property and the method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have stored the gold values for both properties in our dictionaries `gold_birthyears` and `gold_manufacturers`, and written the evaluation function, we need to obtain the system output as well and then perform evaluation.\n",
    "\n",
    "For this purpose, we will run our extractors on texts about the same 50 people and 50 devices from Wikipedia. As in the explanation notebook, we will use the `Wikipedia` library for this purpose. Same as in the explanation notebook, we will only process the first three sentences.\n",
    "\n",
    "In exercises 3a and 3b, we will run all our four processing functions and store the results in four different dictionaries. \n",
    "Then, in exercise 3c, we will run the evaluation function four times to compute precision, recall, and F1-score for all four functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3a** Run your two extractors about birth years of people (from exercise 1a and 1b) on all 50 documents about people. Save the extracted values in two different dictionaries: `birthyear_regex` and `birthyear_dep`. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Al Pacino', 'Alan Rickman', 'Albert Finney', 'Alyson Hannigan', 'Andie MacDowell', 'Andrew Lloyd Webber', 'Andrzej Wajda', 'Andrzej Żuławski', 'Angela Davis', 'Anthony Quinn', 'Antonio Banderas', 'Ashley Judd', 'Ava Gardner', 'Barbara Stanwyck', 'Ben Elton', 'Bernardo Bertolucci', 'Betty Marsden', 'Billy Wilder', 'Blake Edwards', 'Bob Black', 'Bob Keeshan', 'Brad Pitt', 'Cameron Diaz', 'Carmen Miranda', 'Carole Lombard', 'Catherine Deneuve', 'Cesare Zavattini', 'Chandra Levy', 'Charlton Heston', 'Chaz Bono', 'Christine McVie', 'Christopher Lambert', 'Christopher Lee', 'Clark Gable', 'Clint Eastwood', 'Clive Sinclair', 'Cybill Shepherd', 'Dan Aykroyd', 'Dannii Minogue', 'Dave Cutler', 'David Blaine', 'David Boies', 'David Gauthier', 'David Jason', 'David Niven', 'Denise Richards', 'Desmond Llewelyn', 'Don Siegel', 'Dudley Moore', 'Dustin Hoffman']\n",
      "Al Pacino\n"
     ]
    },
    {
     "ename": "PageError",
     "evalue": "Page id \"al pacion\" does not match any pages. Try another id!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPageError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ef34b13e8770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwiki_people\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mwp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# get the first 3 sentences of a wikipedia article\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfirst_three_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36mpage\u001b[0;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# if there is no suggestion or search results, the page doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpageid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either a title or a pageid must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self, redirect, preload)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'missing'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPageError\u001b[0m: Page id \"al pacion\" does not match any pages. Try another id!"
     ]
    }
   ],
   "source": [
    "texts_p={}\n",
    "print(wiki_people)\n",
    "\n",
    "for entity in wiki_people:\n",
    "    print(entity)\n",
    "    wp = wikipedia.page(entity)\n",
    "    # get the first 3 sentences of a wikipedia article\n",
    "    first_three_sentences=wp.content.split('.')[:3]\n",
    "    entity_text=('.').join(first_three_sentences)\n",
    "    # create a dictionary (JSON) where the key is your entity, and the value is its 3-sentences wikipedia text. \n",
    "    texts_p[entity]=entity_text\n",
    "    print(entity_text)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Al Pacino', 'Alan Rickman', 'Albert Finney', 'Alyson Hannigan', 'Andie MacDowell', 'Andrew Lloyd Webber', 'Andrzej Wajda', 'Andrzej Żuławski', 'Angela Davis', 'Anthony Quinn', 'Antonio Banderas', 'Ashley Judd', 'Ava Gardner', 'Barbara Stanwyck', 'Ben Elton', 'Bernardo Bertolucci', 'Betty Marsden', 'Billy Wilder', 'Blake Edwards', 'Bob Black', 'Bob Keeshan', 'Brad Pitt', 'Cameron Diaz', 'Carmen Miranda', 'Carole Lombard', 'Catherine Deneuve', 'Cesare Zavattini', 'Chandra Levy', 'Charlton Heston', 'Chaz Bono', 'Christine McVie', 'Christopher Lambert', 'Christopher Lee', 'Clark Gable', 'Clint Eastwood', 'Clive Sinclair', 'Cybill Shepherd', 'Dan Aykroyd', 'Dannii Minogue', 'Dave Cutler', 'David Blaine', 'David Boies', 'David Gauthier', 'David Jason', 'David Niven', 'Denise Richards', 'Desmond Llewelyn', 'Don Siegel', 'Dudley Moore', 'Dustin Hoffman']\n",
      "entity is Al Pacino\n",
      "manu_predicates ['manufactured', 'produced', 'developed by', 'developed']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Al Pacino'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-16097916a386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'entity is'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'manu_predicates'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmanu_predicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mborn_relations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_birth_year_dep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborn_patterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relation  is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mborn_relations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Al Pacino'"
     ]
    }
   ],
   "source": [
    "birthyear_regex={} \n",
    "birthyear_dep={}\n",
    "\n",
    "texts_p\n",
    "print(wiki_people)\n",
    "born_patterns=['born in', 'birthdate', 'born on']\n",
    "\n",
    "for entity in wiki_people:\n",
    "    print('entity is',entity)\n",
    "    print('manu_predicates',manu_predicates)\n",
    "    print(nlp(texts_p[entity]))\n",
    "    born_relations=extract_birth_year_dep(nlp(texts_p[entity]), born_patterns)\n",
    "    print(\"relation  is\",born_relations)\n",
    "    print()\n",
    "    birthyear_dep.update(born_relations)\n",
    "    #manufacturers_dep[entity]=manu_relation[1]\n",
    "    \n",
    "    \n",
    "\n",
    "for entity in wiki_people:\n",
    "    print('entity is',entity)\n",
    "    print('manu_predicates',manu_predicates)\n",
    "    print(nlp(texts_p[entity]))\n",
    "    born_relations=extract_birth_year_regex(nlp(texts_p[entity]), born_patterns)\n",
    "    print(\"relation  is\",born_relations)\n",
    "    print()\n",
    "    birthyear_regex.update(born_relations)\n",
    "    #manufacturers_dep[entity]=manu_relation[1]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3b** Run your extractors about manufacturers of devices (from exercise 2a and 2b) on all 50 documents about devices. Make sure you only process the first three sentences from each document. Save the extracted values in two lists: `manufacturers_regex` and `manufacturers_dep`. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3DO Interactive Multiplayer\n",
      "The 3DO Interactive Multiplayer, often called the 3DO, is a home video game console developed by The 3DO Company. Conceived by entrepreneur and Electronic Arts founder Trip Hawkins, the 3DO was not a console manufactured by the company itself, but a series of specifications, originally designed by Dave Needle and R. J\n",
      "\n",
      "PDP-7\n",
      "The PDP-7 was a minicomputer produced by Digital Equipment Corporation as part of the PDP series. Introduced in 1964, shipped since 1965, it was the first to use their Flip-Chip technology. With a cost of US$72,000, it was cheap but powerful by the standards of the time\n",
      "\n",
      "TRS-80 Color Computer\n",
      "The RadioShack TRS-80 Color Computer (later marketed as the Tandy Color Computer and sometimes nicknamed the CoCo) is a line of home computers based on the Motorola 6809 processor. The Tandy Color Computer line started in 1980 with what is now called the CoCo 1 and ended in 1991 with the more powerful CoCo 3. All three CoCo models maintained a high level of software and hardware compatibility, with few programs written for the older model being unable to run on the newer ones\n",
      "\n",
      "Walkman\n",
      "Walkman is a brand of portable media players manufactured by Sony. The original Walkman, released in 1979, was a portable cassette player that changed listening habits by allowing people to listen to music of their choice on the move. It was devised by Sony founders Masaru Ibuka and Akio Morita, who felt Sony's existing portable player was too unwieldy and expensive\n",
      "\n",
      "Sega TeraDrive\n",
      "The TeraDrive (テラドライブ, TeraDoraibu) is an IBM PC compatible system with an integrated Mega Drive, developed by Sega and manufactured by IBM in 1991. The TeraDrive allowed for Mega Drive games to be played the same time as the PC section is being used, as it is possible for the Mega Drive and PC hardware to interact with each other.\n",
      "The system was only released in Japan, as Sega hoped that integrating the then popular Mega Drive console into an IBM PC would attract potential customers wishing to purchase a PC\n",
      "\n",
      "GameCube\n",
      "The Nintendo GameCube (commonly abbreviated as GameCube) is a home video game console released by Nintendo in Japan and North America in 2001 and in the PAL territories in 2002. The sixth-generation console is the successor to the Nintendo 64. It competed with Sony's PlayStation 2 and Microsoft's original Xbox\n",
      "\n",
      "Cray-1\n",
      "The Cray-1 was a supercomputer designed, manufactured and marketed by Cray Research. Announced in 1975, the first Cray-1 system was installed at Los Alamos National Laboratory in 1976. Eventually, over 100 Cray-1's were sold, making it one of the most successful supercomputers in history\n",
      "\n",
      "Sega CD\n",
      "The Sega CD, released as the Mega-CD in most regions outside North America and Brazil, is a CD-ROM accessory for the Sega Genesis designed and produced by Sega as part of the fourth generation of video game consoles. It was released on December 12, 1991 in Japan, October 15, 1992 in North America, and April 2, 1993 in Europe. The Sega CD plays CD-based games and adds hardware functionality such as a faster central processing unit and graphic enhancements\n",
      "\n",
      "32X\n",
      "The 32X is an add-on for the Sega Genesis video game console. Codenamed \"Project Mars\", the 32X was designed to expand the power of the Genesis and serve as a transitional console into the 32-bit era until the release of the Sega Saturn. Independent of the Genesis, the 32X uses its own ROM cartridges and has its own library of games\n",
      "\n",
      "Game Gear\n",
      "{'3DO Interactive Multiplayer': 'The 3DO Interactive Multiplayer, often called the 3DO, is a home video game console developed by The 3DO Company. Conceived by entrepreneur and Electronic Arts founder Trip Hawkins, the 3DO was not a console manufactured by the company itself, but a series of specifications, originally designed by Dave Needle and R. J', 'PDP-7': 'The PDP-7 was a minicomputer produced by Digital Equipment Corporation as part of the PDP series. Introduced in 1964, shipped since 1965, it was the first to use their Flip-Chip technology. With a cost of US$72,000, it was cheap but powerful by the standards of the time', 'TRS-80 Color Computer': 'The RadioShack TRS-80 Color Computer (later marketed as the Tandy Color Computer and sometimes nicknamed the CoCo) is a line of home computers based on the Motorola 6809 processor. The Tandy Color Computer line started in 1980 with what is now called the CoCo 1 and ended in 1991 with the more powerful CoCo 3. All three CoCo models maintained a high level of software and hardware compatibility, with few programs written for the older model being unable to run on the newer ones', 'Walkman': \"Walkman is a brand of portable media players manufactured by Sony. The original Walkman, released in 1979, was a portable cassette player that changed listening habits by allowing people to listen to music of their choice on the move. It was devised by Sony founders Masaru Ibuka and Akio Morita, who felt Sony's existing portable player was too unwieldy and expensive\", 'Sega TeraDrive': 'The TeraDrive (テラドライブ, TeraDoraibu) is an IBM PC compatible system with an integrated Mega Drive, developed by Sega and manufactured by IBM in 1991. The TeraDrive allowed for Mega Drive games to be played the same time as the PC section is being used, as it is possible for the Mega Drive and PC hardware to interact with each other.\\nThe system was only released in Japan, as Sega hoped that integrating the then popular Mega Drive console into an IBM PC would attract potential customers wishing to purchase a PC', 'GameCube': \"The Nintendo GameCube (commonly abbreviated as GameCube) is a home video game console released by Nintendo in Japan and North America in 2001 and in the PAL territories in 2002. The sixth-generation console is the successor to the Nintendo 64. It competed with Sony's PlayStation 2 and Microsoft's original Xbox\", 'Cray-1': \"The Cray-1 was a supercomputer designed, manufactured and marketed by Cray Research. Announced in 1975, the first Cray-1 system was installed at Los Alamos National Laboratory in 1976. Eventually, over 100 Cray-1's were sold, making it one of the most successful supercomputers in history\", 'Sega CD': 'The Sega CD, released as the Mega-CD in most regions outside North America and Brazil, is a CD-ROM accessory for the Sega Genesis designed and produced by Sega as part of the fourth generation of video game consoles. It was released on December 12, 1991 in Japan, October 15, 1992 in North America, and April 2, 1993 in Europe. The Sega CD plays CD-based games and adds hardware functionality such as a faster central processing unit and graphic enhancements', '32X': 'The 32X is an add-on for the Sega Genesis video game console. Codenamed \"Project Mars\", the 32X was designed to expand the power of the Genesis and serve as a transitional console into the 32-bit era until the release of the Sega Saturn. Independent of the Genesis, the 32X uses its own ROM cartridges and has its own library of games'}\n"
     ]
    }
   ],
   "source": [
    "textsdev={}\n",
    "wiki_devices\n",
    "for entity in wiki_devices:\n",
    "    print(entity)\n",
    "    if entity == 'Game Gear':\n",
    "        break    # break here\n",
    "    wp = wikipedia.page(entity)\n",
    "    # get the first 3 sentences of a wikipedia article\n",
    "    first_three_sentences=wp.content.split('.')[:3]\n",
    "    entity_text=('.').join(first_three_sentences)\n",
    "    # create a dictionary (JSON) where the key is your entity, and the value is its 3-sentences wikipedia text. \n",
    "    textsdev[entity]=entity_text\n",
    "    print(entity_text)\n",
    "    print()\n",
    "    \n",
    "print(textsdev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3DO Interactive Multiplayer', 'PDP-7', 'TRS-80 Color Computer', 'Walkman', 'Sega TeraDrive', 'GameCube', 'Cray-1', 'Sega CD', '32X', 'Game Gear', 'Sega Saturn', 'TRS-80', 'Vectrex', 'PalmPilot', 'ZX81', 'Volkswagen D24TIC engine', 'Volkswagen D24T engine', 'Volkswagen D24 engine', 'Spice MI-335 (Stellar Craze)', 'Spice Stellar Nhance Mi-435', 'Arirang (smartphone)', 'Micro-Professor MPF-I', 'HTC Touch Diamond2', 'HTC Touch 3G', 'HTC Touch Viva', 'Aakash (tablet)', 'Typekit', 'IPod Mini', 'Mac Mini', 'BMW M2B15', 'Coleco Gemini', 'Zune HD', 'Zune 30', 'Zune 4, 8, 16', 'Zune 80, 120', 'Motorola Hint QA30', 'Motorola W233', 'Motodext', 'Motorola A3100', 'Motorola Aura', 'Motorola Calgary', 'Motorola Photon Q', 'Motorola i1', 'NES Advantage', 'Game Boy', 'Nokia 6210 Navigator', 'Nokia 6710 Navigator', 'Nokia 5320 XpressMusic']\n",
      "entity is 3DO Interactive Multiplayer\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The 3DO Interactive Multiplayer, often called the 3DO, is a home video game console developed by The 3DO Company. Conceived by entrepreneur and Electronic Arts founder Trip Hawkins, the 3DO was not a console manufactured by the company itself, but a series of specifications, originally designed by Dave Needle and R. J\n",
      "relation  is {}\n",
      "\n",
      "entity is PDP-7\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The PDP-7 was a minicomputer produced by Digital Equipment Corporation as part of the PDP series. Introduced in 1964, shipped since 1965, it was the first to use their Flip-Chip technology. With a cost of US$72,000, it was cheap but powerful by the standards of the time\n",
      "relation  is {}\n",
      "\n",
      "entity is TRS-80 Color Computer\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The RadioShack TRS-80 Color Computer (later marketed as the Tandy Color Computer and sometimes nicknamed the CoCo) is a line of home computers based on the Motorola 6809 processor. The Tandy Color Computer line started in 1980 with what is now called the CoCo 1 and ended in 1991 with the more powerful CoCo 3. All three CoCo models maintained a high level of software and hardware compatibility, with few programs written for the older model being unable to run on the newer ones\n",
      "relation  is {}\n",
      "\n",
      "entity is Walkman\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "Walkman is a brand of portable media players manufactured by Sony. The original Walkman, released in 1979, was a portable cassette player that changed listening habits by allowing people to listen to music of their choice on the move. It was devised by Sony founders Masaru Ibuka and Akio Morita, who felt Sony's existing portable player was too unwieldy and expensive\n",
      "relation  is {}\n",
      "\n",
      "entity is Sega TeraDrive\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The TeraDrive (テラドライブ, TeraDoraibu) is an IBM PC compatible system with an integrated Mega Drive, developed by Sega and manufactured by IBM in 1991. The TeraDrive allowed for Mega Drive games to be played the same time as the PC section is being used, as it is possible for the Mega Drive and PC hardware to interact with each other.\n",
      "The system was only released in Japan, as Sega hoped that integrating the then popular Mega Drive console into an IBM PC would attract potential customers wishing to purchase a PC\n",
      "relation  is {}\n",
      "\n",
      "entity is GameCube\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The Nintendo GameCube (commonly abbreviated as GameCube) is a home video game console released by Nintendo in Japan and North America in 2001 and in the PAL territories in 2002. The sixth-generation console is the successor to the Nintendo 64. It competed with Sony's PlayStation 2 and Microsoft's original Xbox\n",
      "relation  is {}\n",
      "\n",
      "entity is Cray-1\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The Cray-1 was a supercomputer designed, manufactured and marketed by Cray Research. Announced in 1975, the first Cray-1 system was installed at Los Alamos National Laboratory in 1976. Eventually, over 100 Cray-1's were sold, making it one of the most successful supercomputers in history\n",
      "relation  is {}\n",
      "\n",
      "entity is Sega CD\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The Sega CD, released as the Mega-CD in most regions outside North America and Brazil, is a CD-ROM accessory for the Sega Genesis designed and produced by Sega as part of the fourth generation of video game consoles. It was released on December 12, 1991 in Japan, October 15, 1992 in North America, and April 2, 1993 in Europe. The Sega CD plays CD-based games and adds hardware functionality such as a faster central processing unit and graphic enhancements\n",
      "relation  is {}\n",
      "\n",
      "entity is 32X\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The 32X is an add-on for the Sega Genesis video game console. Codenamed \"Project Mars\", the 32X was designed to expand the power of the Genesis and serve as a transitional console into the 32-bit era until the release of the Sega Saturn. Independent of the Genesis, the 32X uses its own ROM cartridges and has its own library of games\n",
      "relation  is {}\n",
      "\n",
      "entity is 3DO Interactive Multiplayer\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The 3DO Interactive Multiplayer, often called the 3DO, is a home video game console developed by The 3DO Company. Conceived by entrepreneur and Electronic Arts founder Trip Hawkins, the 3DO was not a console manufactured by the company itself, but a series of specifications, originally designed by Dave Needle and R. J\n",
      "relation  is {}\n",
      "\n",
      "entity is PDP-7\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The PDP-7 was a minicomputer produced by Digital Equipment Corporation as part of the PDP series. Introduced in 1964, shipped since 1965, it was the first to use their Flip-Chip technology. With a cost of US$72,000, it was cheap but powerful by the standards of the time\n",
      "relation  is {}\n",
      "\n",
      "entity is TRS-80 Color Computer\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The RadioShack TRS-80 Color Computer (later marketed as the Tandy Color Computer and sometimes nicknamed the CoCo) is a line of home computers based on the Motorola 6809 processor. The Tandy Color Computer line started in 1980 with what is now called the CoCo 1 and ended in 1991 with the more powerful CoCo 3. All three CoCo models maintained a high level of software and hardware compatibility, with few programs written for the older model being unable to run on the newer ones\n",
      "relation  is {}\n",
      "\n",
      "entity is Walkman\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "Walkman is a brand of portable media players manufactured by Sony. The original Walkman, released in 1979, was a portable cassette player that changed listening habits by allowing people to listen to music of their choice on the move. It was devised by Sony founders Masaru Ibuka and Akio Morita, who felt Sony's existing portable player was too unwieldy and expensive\n",
      "relation  is {}\n",
      "\n",
      "entity is Sega TeraDrive\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The TeraDrive (テラドライブ, TeraDoraibu) is an IBM PC compatible system with an integrated Mega Drive, developed by Sega and manufactured by IBM in 1991. The TeraDrive allowed for Mega Drive games to be played the same time as the PC section is being used, as it is possible for the Mega Drive and PC hardware to interact with each other.\n",
      "The system was only released in Japan, as Sega hoped that integrating the then popular Mega Drive console into an IBM PC would attract potential customers wishing to purchase a PC\n",
      "relation  is {}\n",
      "\n",
      "entity is GameCube\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The Nintendo GameCube (commonly abbreviated as GameCube) is a home video game console released by Nintendo in Japan and North America in 2001 and in the PAL territories in 2002. The sixth-generation console is the successor to the Nintendo 64. It competed with Sony's PlayStation 2 and Microsoft's original Xbox\n",
      "relation  is {}\n",
      "\n",
      "entity is Cray-1\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The Cray-1 was a supercomputer designed, manufactured and marketed by Cray Research. Announced in 1975, the first Cray-1 system was installed at Los Alamos National Laboratory in 1976. Eventually, over 100 Cray-1's were sold, making it one of the most successful supercomputers in history\n",
      "relation  is {}\n",
      "\n",
      "entity is Sega CD\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The Sega CD, released as the Mega-CD in most regions outside North America and Brazil, is a CD-ROM accessory for the Sega Genesis designed and produced by Sega as part of the fourth generation of video game consoles. It was released on December 12, 1991 in Japan, October 15, 1992 in North America, and April 2, 1993 in Europe. The Sega CD plays CD-based games and adds hardware functionality such as a faster central processing unit and graphic enhancements\n",
      "relation  is {}\n",
      "\n",
      "entity is 32X\n",
      "manu_predicates ['manufactured', 'produced', 'developed']\n",
      "The 32X is an add-on for the Sega Genesis video game console. Codenamed \"Project Mars\", the 32X was designed to expand the power of the Genesis and serve as a transitional console into the 32-bit era until the release of the Sega Saturn. Independent of the Genesis, the 32X uses its own ROM cartridges and has its own library of games\n",
      "relation  is {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manufacturers_regex={}\n",
    "manufacturers_dep={}\n",
    "textsdev\n",
    "print(wiki_devices)\n",
    "manu_predicates=['manufactured', 'produced', 'developed']\n",
    "\n",
    "for entity in wiki_devices:\n",
    "    if entity == 'Game Gear':\n",
    "        break    # break here\n",
    "    print('entity is',entity)\n",
    "    print('manu_predicates',manu_predicates)\n",
    "    print(nlp(textsdev[entity]))\n",
    "    manu_relations=extract_manufacturer(nlp(textsdev[entity]), manu_predicates, entity)\n",
    "    print(\"relation  is\",manu_relations)\n",
    "    print()\n",
    "    manufacturers_dep.update(manu_relations)\n",
    "    #manufacturers_dep[entity]=manu_relation[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "for entity in wiki_devices:\n",
    "    if entity == 'Game Gear':\n",
    "        break    # break here\n",
    "    print('entity is',entity)\n",
    "    print('manu_predicates',manu_predicates)\n",
    "    print(nlp(textsdev[entity]))\n",
    "    manu_relations=extract_manufacturer_regex(nlp(textsdev[entity]), manu_predicates, entity)\n",
    "    print(\"relation  is\",manu_relations)\n",
    "    print()\n",
    "    manufacturers_regex.update(manu_relations)\n",
    "    #manufacturers_regex[entity]=manu_relation[1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3c** Run the evaluation function `evaluate_property` to compute the performance for each of your four functions. Print the precision, recall, and F1-scores. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'birthyear_regex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-d778d73dbb18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbirthyear_regex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_birthyears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanufacturers_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_manufacturers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbirthyear_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_birthyears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanufacturers_regex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_manufacturers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'birthyear_regex' is not defined"
     ]
    }
   ],
   "source": [
    "print(utils.evaluate_property(birthyear_regex, gold_birthyears))\n",
    "print(utils.evaluate_property(manufacturers_dep, gold_manufacturers))\n",
    "\n",
    "print(utils.evaluate_property(birthyear_dep, gold_birthyears))\n",
    "print(utils.evaluate_property(manufacturers_regex, gold_manufacturers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Reflection (8 points)\n",
    "\n",
    "For each entity, we will now compare the two methods to extract properties in terms of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4a** Comparing the precision between the methods based on regular expressions and on syntax dependencies:\n",
    "* Which method yields lower precision?\n",
    "* Why do you think this is the case?\n",
    "* Give an example to support your argument.\n",
    "\n",
    "(4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4b** Let's compare the recall for both properties. \n",
    "* Which method yields lower recall?\n",
    "* Why do you think this is the case?\n",
    "* Give an example to support your argument.\n",
    "\n",
    "(4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
